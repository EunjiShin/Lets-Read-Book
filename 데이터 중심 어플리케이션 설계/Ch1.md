## 데이터 시스템에 대한 생각

> 💡 계산 중심이 아니라 데이터 중심의 애플리케이션이 되면서 데이터의 양 / 복잡도 / 변화 속도가 중요해짐

- DB, 큐, 캐시 등은 서로 다른 접근 패턴과 성능 특성을 갖기에 구현 방식이 매우 다르고, 따라서 매우 다른 범주에 속한 도구로 본다.
- 하지만 이들은 다음의 이유로 `데이터 시스템`이라는 포괄적 용어로 묶인다.
    - **최근에 만들어진 도구들은 다양한 use case에 최적화되기에, 전통적인 분류의 경계가 존재하지 않는다.**
        - ex. DB인 redis를 메세지 큐 처럼 사용하는 사례
    - **광범위한 요구사항을 단일 도구로 구현할 수 없다.**
        - 따라서 요구사항을 단일 도구에서 수행할 수 있는 task로 쪼개고, 이들을 연결하여 구현해야 한다.

---

## 신뢰성

> 💡 결함 또는 장애 발생시에도 시스템은 지속적으로 올바르게 기능을 수행해야 한다.

- 결함 ≠ 장애
    - 결함 : 사양에서 벗어난 시스템의 한 구성 요소
    - 장애 : 시스템 전체가 서비스를 제공하지 못하고 멈춘 경우
- 결함을 100% 방지하는 것은 불가능하므로, 모든 결함을 예방하기 위해 노력하는 것보단 **결함으로 인해 장애가 발생하지 않도록 내결함성 구조를 설계**하는 것이 중요하다.
    - 내결함성 : 결함을 예측하고 대처할 수 있는 시스템 (= 탄력성을 지닌 시스템)

> ❄️ **넷플릭스의 카오스 몽키** <br>
> : 일부러 시스템 결함을 발생시키고, 엔지니어들은 그 결함에 대한 장애 대응 메커니즘을 구축하는 과정을 통해 장애를 미리 테스트 & 방지하는 도구


### 하드웨어 결함

> 리터럴리 하드웨어에 문제가 생긴 것 (ex. 하드디스크 고장, 대규모 정전 사태, 화재 etc…)

1. 각 하드웨어 구성 요소에 중복을 추가하여 예방하기.
    1. 구성 요소 중 하나가 죽으면, 멀쩡한 다른 구성 요소로 대체하는 방식
2. 소프트웨어 내결함성 기술 또는 하드웨어 중복성을 추가하여 전체 장비 손실을 예방하기.
    1. 애플리케이션이 커지면서 더 많은 장비를 사용하게 됨에 따라, 단일 장비 신뢰성보단 유연성과 탄력성이 중요해졌기 때문에 등장한 방식

### 소프트웨어 오류

> 하드웨어는 말짱한데 소프트웨어에 문제가 있는 경우

- 시스템 내의 체계적 오류가 원인으로, 실제 발생 전까지 예측하기도 어렵고 신속한 해결책도 없다.
- 따라서 애초에 발생하지 않도록 꼼꼼히 보는 것, 그리고 발생했을 때 빠르게 관측하는 것이 중요
    - 테스트, 프로세스 격리, 시스템에 대한 깊은 생각, 죽은 프로세스의 재시작, 모니터링…

### 인적 오류

> 기계는 잘못이 없는데 내가 잘못한 경우

- 사람은 어떤 방식으로든 실수를 하기 때문에, 시스템적으로 오류를 방지하도록 설계해야 한다.
    - 철저한 테스트, 복구 및 모니터링 대책, 조작 교육 등

### 신뢰성은 얼마나 중요할까?

- 신뢰성은 안정성 뿐만 아니라 생산성에도 영향을 준다.
- 모든 애플리케이션은 사용자에 대한 책임을 가지며, 따라서 사소한 서비스라도 안정적으로 작동해야 한다.
    - 비용 감소를 위해 신뢰성을 희생하되, 비용을 줄일 시점을 잘 정해야 한다.

---

## 확장성

> 💡 시스템의 규모가 커져도 처리할 수 있는 방법이 있어야 한다.

- 시스템이 지금 잘 동작한다고 해서 앞으로도 쭉 안정적일 것이라는 보장은 없다.
    - 성능 저하는 주로 부하 증가(동시 사용자 수의 증가, 처리량의 증가 등)에 의해 발생한다.
- 확장성을 논한다는 것은 아래의 문제 등을 고려한다는 의미다.
    1. 시스템이 특정 방식으로 커지면 어떻게 대처할 수 있을까?
    2. 추가 부하를 다루기 위해 계산 자원을 어떻게 투입해야 할까?

### 부하 기술하기

> 시스템의 현재 부하를 알아야 부하가 생겼을 때의 대책을 논의할 수 있다.

- 부하 매개변수를 이용해 부하를 표현할 수 있다.
    - 웹 서버의 초당 요청 수 (RPS)
    - 데이터베이스의 읽기 대 쓰기 비율
    - 동시 활성 사용자 (active user)
    - 캐시 적중률 (cache hit ratio)
- 부하는 평균적인 경우가 핵심 요소인 경우도 있고, 소수의 극단적인 경우가 핵심인 경우도 있다.

> ❄️ **트위터의 타임라인 최적화** <br>
> 1. 트위터는 일반적으로 write 량 <<<< (넘사벽) <<<< read 량이다. <br>
> 2. 하지만 팔로워가 많은 특정 사용자에 대해선 오히려 write 부하가 매우 크다. <br>
> 3. 따라서 평균적인 경우에는 FOOW 모델을, 팔로워수가 많은 유저의 경우에는 FOOR 모델을 쓴다. <br>
> ⇒ 즉, 팔로워 수가 핵심 부하 매개변수이니 팔로워 수에 따라 팬 아웃 방식을 분기한 사례.


### 성능 기술하기

> 시스템 부하를 기술하면 부하가 증가했을 때 어떤 일이 생길지 예측할 수 있다.

- 일반적으로 아래 두 방법을 이용해 예측할 수 있다.
    1. 부하가 증가했을 때, 시스템 자원을 변경하지 않으면 시스템 성능은 어떤 영향을 받을까?
    2. 부하가 증가했을 때, 성능이 변하지 않고 유지되려면 시스템 자원을 얼마나 늘려야 할까?
- 위 질문을 해결하기 위해 시스템 성능을 기술해야 한다. 다음은 시스템 유형에 따른 성능 지표이다.
    1. `일괄 처리 시스템`
       → 처리량 (throughput / 초당 처리 가능한 레코드 수, 일정 크기의 데이터 집합으로 작업을 수행할때 걸리는 전체 시간 등)
    2. `온라인 시스템 (OLTP)`
       → 서비스 응답 시간 (response time / 클라가 요청을 보내고 응답을 받는 사이의 시간)
       → 단, 응답 시간은 단일 숫자가 아니라 분포로 생각해야 하며, 평균보단 백분위를 측정하는게 중요하다.
       → 특히 꼬리 지연 시간 (= 상위 백분위 응답 시간. p999 등)이 중요!

### 부하 대응 접근 방식

> 부하가 증가해도 좋은 성능을 유지하려면 어떻게 해야 하는가?

- `용량 확장 (= scaling up = 수직 확장)`
    - 좀 더 좋은 장비를 쓰자!
- `규모 확장 (= scaling out = 수평 확장. 비공유 아키텍처)`
    - 좀 더 많은 장비를 쓰자!
    - 보통 고사양 장비는 아주 비싸므로 대부분의 경우 규모 확장이 필요하다.
    - 장점
        - 탄력적 시스템 구축
            - 부하 증가를 감지하면 컴퓨팅 자원을 자동으로 추가한다.
        - 상태 비저장 (state-less) 서비스 배포가 간단함
            - stateful한 서비스라면 반대로 아주 복잡함 (동기화이슈!)

> ❄️ 대규모 시스템 아키텍처는 해당 시스템 애플리케이션에 특화되어 있다. <br>
> 범용적이고 모든 상황에 맞는 확장 아키텍처는 없다는 점을 명심하자. <br>
> 주요 동작, 잘 하지 않는 동작이 무엇인지를 기반으로 **적절한 부하 매개변수를 갖추어 설계**하는게 중요!


---

## 유지보수성

> 💡 시스템은 모든 사례에서 생산적이어야 한다.

### 운용성

> 운영팀이 운영하기 쉽게 만들어라

- 아무리 좋은 소프트웨어라도 나쁘게 운영하면 작동을 신뢰할 수 없다.
- 반복되는 노가다성 작업들을 `자동화`하여 운영팀이 고부가가치 활동에 집중하게 하는게 중요하다.

### 단순성

> 새로운 엔지니어가 이해하기 쉽게 만들어라

- 프로젝트가 커질수록 시스템은 복잡하고 이해하기 어려워진다.
- 복잡도는 예산과 일정을 초과하는 주범이 되곤 하므로, 생산성, 유지보수성을 위해 단순하게 만들어야 한다.
    - `추상화`를 이용해 세부 구현을 숨겨 시스템을 단순하게 만들자.

### 발전성

> 이후 쉽게 변경 가능하도록 만들어라

- 시스템 요구사항은 끊임없이 변한다.
- 따라서 시스템을 간단하고 이해하기 쉽게 만들어 시스템 수준에서 `민첩성`을 높여야 한다.